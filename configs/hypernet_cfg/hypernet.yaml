defaults:
  - base_hypernet


# These will be automatically resolved from the used environment.
reward_dim: "${env.reward_dim:${..training_cfg.env_id}}"
obs_dim: "${env.obs_dim:${..training_cfg.env_id}}"
action_dim: "${env.action_dim:${..training_cfg.env_id}}"

head_hidden_dim: 1024
activation_fn: "relu"
layer_dims: 
  - 256
  - "${..reward_dim}"

resblock_arch:
    - n_resblocks: 2
      # This will be automatically resolved with reward_dim + obs_dim
      input_dim: "${sum:${...obs_dim}, ${...reward_dim}}"
      output_dim: 256
      activation_fn: "relu"
      network_arch:
        - 256
        - 256
    - n_resblocks: 2
      input_dim: 256 
      output_dim: 512
      activation_fn: "relu"
      network_arch: 
        - 512
        - 512
    - n_resblocks: 2
      input_dim: 512
      output_dim: 1024
      activation_fn: "relu"
      network_arch:
        - 1024
        - 1024




